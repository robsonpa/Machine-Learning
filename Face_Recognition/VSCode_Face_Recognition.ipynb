{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdh79SX18fPR"
      },
      "source": [
        "**Sistema de Reconhecimento facial ao vivo em tempo real.**\n",
        "\n",
        "**Projeto Final:** EY Fast Track Specialist - Machine Learning\n",
        "\n",
        "Este projeto foi construido usando a rede de reconhecimento facial do python dlib e APIs face_recognition (do OpenCV). Dlib é uma biblioteca de software de uso geral.\n",
        "\n",
        "Implementamos este projeto python em duas partes:\n",
        "\n",
        "1. Na primeira parte, armazenamos as informações sobre a estrutura da face humana, ou seja, a incorporação da face. Em seguida, armazenamos esses embeddings.\n",
        "\n",
        "2. Na segunda parte, reconhecer a pessoa comparando os novos rostos incorporados com os armazenados.\n",
        "\n",
        "Robson de Abreu Parreiras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FRlGEb6-Hn6"
      },
      "source": [
        "Instalar os pacotes\n",
        "\n",
        "Instalaçao no windows 10 -> https://www.geeksforgeeks.org/how-to-install-dlib-library-for-python-in-windows-10/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM4HVGKl8aHY",
        "outputId": "3bb1ba67-a518-491b-d4ad-8768e0d3bd9d"
      },
      "outputs": [],
      "source": [
        "#pip install --upgrade pip\n",
        "#pip install cmake\n",
        "#pip install dlib\n",
        "#pip install face_recognition\n",
        "#pip install opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei816NKo-Y6p"
      },
      "source": [
        "Nesta etapa, capturamos imagens da pessoa e faremos os embeddings de rosto dessas imagens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Noo_rtWN-l9I"
      },
      "source": [
        "Importando as bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H3VhuIhj-h01"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import face_recognition\n",
        "import cv2 \n",
        "import pickle\n",
        "#from IPython.display import display, Javascript\n",
        "#from base64 import b64decode\n",
        "#from IPython.display import Image\n",
        "#from PIL import Image as Img\n",
        "import numpy as np\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Haq65uOP-y2l"
      },
      "source": [
        "Para identificar a pessoa em um arquivo pickle, pegue seu nome e um id exclusivo como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHDXsrdh-0wc",
        "outputId": "11d4276b-4f82-45a5-adfd-60686276ed26"
      },
      "outputs": [],
      "source": [
        "name=input(\"Digite seu nome: \")\n",
        "ref_id=input(\"Digite seu id: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1dUn3ucMloA"
      },
      "source": [
        "Crie um arquivo pickle e um dicionário para armazenar codificações de rosto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DqB18KqgMJMm"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    f=open(\"ref_name.pkl\",\"rb\")\n",
        "    ref_dictt=pickle.load(f)\n",
        "    f.close()\n",
        "except:\n",
        "    ref_dictt={}\n",
        "ref_dictt[ref_id]=name\n",
        "f=open(\"ref_name.pkl\",\"wb\")\n",
        "pickle.dump(ref_dictt,f)\n",
        "f.close()\n",
        "try:\n",
        "    f=open(\"ref_embed.pkl\",\"rb\")\n",
        "    embed_dictt=pickle.load(f)\n",
        "    f.close()\n",
        "except:\n",
        "    embed_dictt={}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYOU6FEBMbAK"
      },
      "source": [
        "\n",
        "Abra a webcam e tire 5 fotos de uma pessoa e crie seus embeddings:\n",
        "\n",
        "Para capturar imagens, pressione 's' cinco vezes. Se você quiser parar a câmera, pressione 'q':\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "xahftfZzMZb-",
        "outputId": "8147cc3f-7773-455c-b336-660089cb73fd"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "    key = cv2. waitKey(1)\n",
        "    webcam = cv2.VideoCapture(0)\n",
        "    while True:\n",
        "       \n",
        "        check, frame = webcam.read()\n",
        "        cv2.imshow(\"Capturing\", frame)\n",
        "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
        "        rgb_small_frame = small_frame[:, :, ::-1]\n",
        "  \n",
        "        key = cv2.waitKey(1)\n",
        "        if key == ord('s') : \n",
        "            face_locations = face_recognition.face_locations(rgb_small_frame)\n",
        "            if face_locations != []:\n",
        "                face_encoding = face_recognition.face_encodings(frame)[0]\n",
        "                if ref_id in embed_dictt:\n",
        "                    embed_dictt[ref_id]+=[face_encoding]\n",
        "                else:\n",
        "                    embed_dictt[ref_id]=[face_encoding]\n",
        "                webcam.release()\n",
        "                cv2.waitKey(1)\n",
        "                cv2.destroyAllWindows()     \n",
        "                break\n",
        "        elif key == ord('q'):\n",
        "            print(\"Turning off camera.\")\n",
        "            webcam.release()\n",
        "            print(\"Camera off.\")\n",
        "            print(\"Program ended.\")\n",
        "            cv2.destroyAllWindows()\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffA8d_7jP-Lc"
      },
      "source": [
        "Aqui nós armazenamos o embed_dictt em um arquivo pickle. Portanto, para reconhecer essa pessoa no futuro, podemos carregar diretamente seus embeddings a partir deste arquivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WxV_Eby2P-dz"
      },
      "outputs": [],
      "source": [
        "f=open(\"ref_embed.pkl\",\"wb\")\n",
        "pickle.dump(embed_dictt,f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvQReWI4gmAn"
      },
      "source": [
        "Carregue os arquivos de picles armazenados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "csp1fzBFgvCy"
      },
      "outputs": [],
      "source": [
        "f=open(\"ref_name.pkl\",\"rb\")\n",
        "ref_dictt=pickle.load(f)        \n",
        "f.close()\n",
        "f=open(\"ref_embed.pkl\",\"rb\")\n",
        "embed_dictt=pickle.load(f)      \n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6xsFup0g6Ds"
      },
      "source": [
        "Crie duas listas, uma para armazenar ref_id e outra para a respectiva incorporação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JTWVm-Z5g9xy"
      },
      "outputs": [],
      "source": [
        "known_face_encodings = []  \n",
        "known_face_names = []  \n",
        "for ref_id , embed_list in embed_dictt.items():\n",
        "    for my_embed in embed_list:\n",
        "        known_face_encodings +=[my_embed]\n",
        "        known_face_names += [ref_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qanO70OphISq"
      },
      "source": [
        "Inicie a webcam para reconhecer a pessoa \n",
        "pressione 'q' para fechar o camera"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "m1NeF7N2hJjk",
        "outputId": "69978894-b468-495f-9b83-aa733f2247f5"
      },
      "outputs": [],
      "source": [
        "video_capture = cv2.VideoCapture(0)\n",
        "face_locations = []\n",
        "face_encodings = []\n",
        "face_names = []\n",
        "process_this_frame = True\n",
        "while True  :\n",
        "  \n",
        "    ret, frame = video_capture.read()\n",
        "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
        "    rgb_small_frame = small_frame[:, :, ::-1]\n",
        "    if process_this_frame:\n",
        "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
        "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
        "        face_names = []\n",
        "        for face_encoding in face_encodings:\n",
        "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
        "            name = \"Unknown\"\n",
        "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
        "            best_match_index = np.argmin(face_distances)\n",
        "            if matches[best_match_index]:\n",
        "                name = known_face_names[best_match_index]\n",
        "            face_names.append(name)\n",
        "    process_this_frame = not process_this_frame\n",
        "    for (top_s, right, bottom, left), name in zip(face_locations, face_names):\n",
        "        top_s *= 4\n",
        "        right *= 4\n",
        "        bottom *= 4\n",
        "        left *= 4\n",
        "        cv2.rectangle(frame, (left, top_s), (right, bottom), (0, 0, 255), 2)\n",
        "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
        "        font = cv2.FONT_HERSHEY_DUPLEX\n",
        "        cv2.putText(frame, ref_dictt[name], (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
        "    font = cv2.FONT_HERSHEY_DUPLEX\n",
        "    cv2.imshow('Video', frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "f72f5f55390904a9a38908aa573b1a60bd7dd01e0497984e909bf0b27382fbca"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
